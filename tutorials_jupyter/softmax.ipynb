{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855f0464-5942-4f23-ad14-905a9ad9a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "from numba.cuda import as_cuda_array\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton.runtime import driver\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def numba_softmax_kernel(x, y, num_rows, num_cols):\n",
    "    \"\"\"Softmax kernel - same as before\"\"\"\n",
    "    row = cuda.blockIdx.x\n",
    "    tid = cuda.threadIdx.x\n",
    "    block_size = cuda.blockDim.x\n",
    "    \n",
    "    shared_max = cuda.shared.array(1024, float32)\n",
    "    shared_sum = cuda.shared.array(1024, float32)\n",
    "    \n",
    "    if row >= num_rows:\n",
    "        return\n",
    "    \n",
    "    # Step 1: Find max\n",
    "    thread_max = float('-inf')\n",
    "    for col in range(tid, num_cols, block_size):\n",
    "        val = x[row, col]\n",
    "        if val > thread_max:\n",
    "            thread_max = val\n",
    "    \n",
    "    shared_max[tid] = thread_max\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    stride = block_size // 2\n",
    "    while stride > 0:\n",
    "        if tid < stride:\n",
    "            if shared_max[tid + stride] > shared_max[tid]:\n",
    "                shared_max[tid] = shared_max[tid + stride]\n",
    "        cuda.syncthreads()\n",
    "        stride //= 2\n",
    "    \n",
    "    row_max = shared_max[0]\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Step 2: Compute exp and sum\n",
    "    thread_sum = 0.0\n",
    "    for col in range(tid, num_cols, block_size):\n",
    "        val = x[row, col] - row_max\n",
    "        exp_val = math.exp(val)\n",
    "        y[row, col] = exp_val\n",
    "        thread_sum += exp_val\n",
    "    \n",
    "    shared_sum[tid] = thread_sum\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    stride = block_size // 2\n",
    "    while stride > 0:\n",
    "        if tid < stride:\n",
    "            shared_sum[tid] += shared_sum[tid + stride]\n",
    "        cuda.syncthreads()\n",
    "        stride //= 2\n",
    "    \n",
    "    row_sum = shared_sum[0]\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Step 3: Normalize\n",
    "    for col in range(tid, num_cols, block_size):\n",
    "        y[row, col] = y[row, col] / row_sum\n",
    "\n",
    "\n",
    "def numba_softmax(x):\n",
    "    \"\"\"\n",
    "    Efficient softmax that works directly with PyTorch CUDA tensors.\n",
    "    \n",
    "    Args:\n",
    "        x: 2D PyTorch CUDA tensor or NumPy array\n",
    "    \n",
    "    Returns:\n",
    "        y: PyTorch CUDA tensor or device array\n",
    "    \"\"\"\n",
    "    # Handle PyTorch tensors\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        if not x.is_cuda:\n",
    "            x = x.cuda()\n",
    "        \n",
    "        # Create output tensor\n",
    "        y = torch.empty_like(x)\n",
    "        \n",
    "        # Get CUDA array interface from PyTorch tensors\n",
    "        # This is zero-copy!\n",
    "        x_numba = cuda.as_cuda_array(x.detach())\n",
    "        y_numba = cuda.as_cuda_array(y)\n",
    "        \n",
    "        # Launch kernel\n",
    "        num_rows, num_cols = x.shape\n",
    "        threads_per_block = min(1024, 2**math.ceil(math.log2(num_cols)))\n",
    "        threads_per_block = max(32, threads_per_block)\n",
    "        blocks = num_rows\n",
    "        \n",
    "        numba_softmax_kernel[blocks, threads_per_block](\n",
    "            x_numba, y_numba, num_rows, num_cols\n",
    "        )\n",
    "        cuda.synchronize()\n",
    "        return y\n",
    "    \n",
    "    # Handle NumPy arrays (original behavior)\n",
    "    else:\n",
    "        x_device = cuda.to_device(x.astype(np.float32))\n",
    "        y_device = cuda.device_array(x_device.shape, dtype=np.float32)\n",
    "        \n",
    "        num_rows, num_cols = x_device.shape\n",
    "        threads_per_block = min(1024, 2**math.ceil(math.log2(num_cols)))\n",
    "        threads_per_block = max(32, threads_per_block)\n",
    "        blocks = num_rows\n",
    "        \n",
    "        numba_softmax_kernel[blocks, threads_per_block](\n",
    "            x_device, y_device, num_rows, num_cols\n",
    "        )\n",
    "        cuda.synchronize()\n",
    "        return y_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ca1b6d-a3ee-4e60-a6a3-13c546b7232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lelarge/miniconda3/envs/cs336-syst/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 100 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (100, 512)\n",
      "Output shape: (100, 512)\n",
      "Max difference: 7.45e-09\n",
      "Row sums (should be ~1.0): [1.        1.        0.9999999 1.        1.       ]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# Usage Example\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test data\n",
    "    M, N = 100, 512  # 100 rows, 512 columns\n",
    "    x = np.random.randn(M, N).astype(np.float32)\n",
    "    \n",
    "    # Compute softmax\n",
    "    y_device = numba_softmax(x)\n",
    "    y = y_device.copy_to_host()\n",
    "    \n",
    "    # Verify with numpy\n",
    "    def numpy_softmax(x):\n",
    "        x_max = np.max(x, axis=1, keepdims=True)\n",
    "        exp_x = np.exp(x - x_max)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    y_expected = numpy_softmax(x)\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {y.shape}\")\n",
    "    print(f\"Max difference: {np.max(np.abs(y - y_expected)):.2e}\")\n",
    "    print(f\"Row sums (should be ~1.0): {y.sum(axis=1)[:5]}\")\n",
    "    print(f\"Match: {np.allclose(y, y_expected, rtol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3345e0-0c64-43bd-8f35-08d6acdf06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def triton_softmax_kernel(x_ptr, y_ptr, x_row_stride, y_row_stride, num_cols, BLOCK_SIZE: tl.constexpr):\n",
    "    assert num_cols <= BLOCK_SIZE\n",
    "    # Process each row independently\n",
    "    row_idx = tl.program_id(0)\n",
    "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    # Read from global memory\n",
    "    x_start_ptr = x_ptr + row_idx * x_row_stride\n",
    "    x_ptrs = x_start_ptr + col_offsets\n",
    "    x_row = tl.load(x_ptrs, mask=col_offsets < num_cols, other=float(\"-inf\"))\n",
    "    # Compute\n",
    "    x_row = x_row - tl.max(x_row, axis=0)\n",
    "    numerator = tl.exp(x_row)\n",
    "    denominator = tl.sum(numerator, axis=0)\n",
    "    y_row = numerator / denominator\n",
    "    # Write back to global memory\n",
    "    y_start_ptr = y_ptr + row_idx * y_row_stride\n",
    "    y_ptrs = y_start_ptr + col_offsets\n",
    "    tl.store(y_ptrs, y_row, mask=col_offsets < num_cols)\n",
    "\n",
    "def triton_softmax(x: torch.Tensor):\n",
    "    # Allocate output tensor\n",
    "    y = torch.empty_like(x)\n",
    "    # Determine grid\n",
    "    M, N = x.shape                          # Number of rows x number of columns\n",
    "    block_size = triton.next_power_of_2(N)  # Each block contains all the columns\n",
    "    num_blocks = M                          # Each block is a row\n",
    "    # Launch kernel\n",
    "    triton_softmax_kernel[(M,)](\n",
    "        x_ptr=x, y_ptr=y,\n",
    "        x_row_stride=x.stride(0), y_row_stride=y.stride(0),\n",
    "        num_cols=N, BLOCK_SIZE=block_size\n",
    "    )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac8c32c-a140-4a97-b724-39672d0a088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(1823, 781, device=DEVICE)\n",
    "y_triton = triton_softmax(x)\n",
    "y_torch = torch.softmax(x, axis=1)\n",
    "assert torch.allclose(y_triton, y_torch), (y_triton, y_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148d1b88-aaa0-47b6-96f5-0d2f4e72bb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax-performance:\n",
      "          N       Triton        Torch       Numba\n",
      "0     256.0   942.599430   962.352543  116.713841\n",
      "1     384.0  1284.997113  1280.739862  125.222578\n",
      "2     512.0  1632.157679  1539.247509  147.621745\n",
      "3     640.0  1775.181088  1601.397047   95.504593\n",
      "4     768.0  1959.073713  1739.864201  109.705874\n",
      "5     896.0  2045.441503  1851.393407  118.742315\n",
      "6    1024.0  2230.360336  2000.460017  125.721024\n",
      "7    1152.0  2226.269206   892.094129  134.913268\n",
      "8    1280.0  2365.972167   969.764271  155.678533\n",
      "9    1408.0  2437.340114  1054.519034  159.851878\n",
      "10   1536.0  2519.855301  1135.368979  169.503572\n",
      "11   1664.0  2541.779291  1178.560340  192.703724\n",
      "12   1792.0  2631.167128  1245.641857  203.364040\n",
      "13   1920.0  2697.423963  1320.546941  219.980579\n",
      "14   2048.0  2702.185582  1386.230323  231.086530\n",
      "15   2176.0  2737.422023  1416.944783  231.736881\n",
      "16   2304.0  2751.662553  1496.467381  245.536246\n",
      "17   2432.0  2796.886312  1558.519602  241.740017\n",
      "18   2560.0  2831.802350  1617.886138  262.280283\n",
      "19   2688.0  2870.359741  1647.673557  275.940323\n",
      "20   2816.0  2900.720871  1713.192733  281.268730\n",
      "21   2944.0  2933.939131  1758.668901  299.494049\n",
      "22   3072.0  2935.639397  1802.773423  275.045938\n",
      "23   3200.0  2986.051161  1852.221055  301.826847\n",
      "24   3328.0  2993.362866  1901.321228  330.182689\n",
      "25   3456.0  3024.058281  1956.103350  334.190892\n",
      "26   3584.0  3037.575161  1980.386811  353.464355\n",
      "27   3712.0  3039.371646  2006.055768  359.164990\n",
      "28   3840.0  3059.029595  2054.803851  368.193539\n",
      "29   3968.0  3074.269156  2084.593618  383.870467\n",
      "30   4096.0  3082.910736  2108.461834  407.381979\n",
      "31   4224.0  2990.742261  1836.124034  413.007688\n",
      "32   4352.0  3008.823767  1842.926600  401.026596\n",
      "33   4480.0  3013.194219  1858.090416  403.000883\n",
      "34   4608.0  3044.741277  1855.824584  425.961243\n",
      "35   4736.0  3056.017832  1900.067009  441.516834\n",
      "36   4864.0  3070.224567  1926.339486  458.378361\n",
      "37   4992.0  3060.285923  1948.380255  469.354102\n",
      "38   5120.0  3081.310469  1977.243533  468.070982\n",
      "39   5248.0  3103.111930  2029.313414  475.045496\n",
      "40   5376.0  3107.409272  2056.771277  460.191619\n",
      "41   5504.0  3125.348137  2084.280114  466.427851\n",
      "42   5632.0  3115.757035  2106.975870  453.475720\n",
      "43   5760.0  3126.065803  2119.143857  492.053067\n",
      "44   5888.0  3140.189825  2148.653782  495.954899\n",
      "45   6016.0  3142.022123  2172.535191  487.642835\n",
      "46   6144.0  3122.273908  2187.957227  509.230007\n",
      "47   6272.0  3149.644743  2224.650721  490.869827\n",
      "48   6400.0  3171.116332  2236.850317  508.360642\n",
      "49   6528.0  3168.500063  2242.820090  508.457614\n",
      "50   6656.0  3181.206044  2280.605617  510.272626\n",
      "51   6784.0  3190.021487  2299.378023  509.910802\n",
      "52   6912.0  3199.035036  2325.731190  536.896551\n",
      "53   7040.0  3185.834954  2332.259370  560.486787\n",
      "54   7168.0  3203.091753  2355.181516  549.357782\n",
      "55   7296.0  3205.194788  2374.421962  575.208391\n",
      "56   7424.0  3214.997563  2383.258373  572.236884\n",
      "57   7552.0  3218.839931  2412.294773  542.295198\n",
      "58   7680.0  3217.298413  2423.675575  601.773448\n",
      "59   7808.0  3227.340973  2428.769345  597.767541\n",
      "60   7936.0  3230.116430  2447.507229  590.151282\n",
      "61   8064.0  3229.356904  2455.509506  606.784447\n",
      "62   8192.0  3231.570622  2457.493728  640.647161\n",
      "63   8320.0  1981.800100  2402.630448  627.797149\n",
      "64   8448.0  2007.129293  2381.529215  657.619874\n",
      "65   8576.0  2043.796262  2358.773059  650.523864\n",
      "66   8704.0  2058.079121  2369.946381  679.517890\n",
      "67   8832.0  2094.562410  2363.969265  657.718094\n",
      "68   8960.0  2128.804543  2371.075906  676.051611\n",
      "69   9088.0  2157.259584  2368.669851  667.776268\n",
      "70   9216.0  2177.558848  2383.755233  658.100457\n",
      "71   9344.0  2195.207720  2392.382502  646.915836\n",
      "72   9472.0  2224.647094  2401.951377  634.031113\n",
      "73   9600.0  2249.670845  2413.638180  651.298951\n",
      "74   9728.0  2275.013089  2430.444936  633.847159\n",
      "75   9856.0  2292.494751  2437.784401  685.718717\n",
      "76   9984.0  2319.772723  2442.615700  686.596815\n",
      "77  10112.0  2336.373948  2468.538219  694.555097\n",
      "78  10240.0  2373.486071  2486.428122  706.755024\n",
      "79  10368.0  2390.807125  2498.656734  703.439631\n",
      "80  10496.0  2419.894669  2514.323932  695.078764\n",
      "81  10624.0  2437.528947  2529.265752  645.795172\n",
      "82  10752.0  2436.197706  2536.730179  685.789877\n",
      "83  10880.0  2477.685440  2546.725757  689.075078\n",
      "84  11008.0  2501.355258  2552.854771  702.422510\n",
      "85  11136.0  2523.265605  2568.185643  709.248192\n",
      "86  11264.0  2564.150926  2576.357638  713.276143\n",
      "87  11392.0  2568.354794  2592.002400  685.502223\n",
      "88  11520.0  2577.233109  2602.869268  723.096063\n",
      "89  11648.0  2609.924073  2605.301029  727.173632\n",
      "90  11776.0  2637.526882  2610.398416  730.591720\n",
      "91  11904.0  2651.531200  2614.985408  744.454829\n",
      "92  12032.0  2665.390633  2622.910121  749.005883\n",
      "93  12160.0  2679.797963  2657.963231  732.446691\n",
      "94  12288.0  2692.714542  1690.597833  771.627913\n",
      "95  12416.0  2729.471237  1656.499819  764.517413\n",
      "96  12544.0  2752.280581  1643.381779  780.303712\n",
      "97  12672.0  2776.722413  1645.145231  787.208605\n"
     ]
    }
   ],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['N'],  # argument names to use as an x-axis for the plot\n",
    "        x_vals=[128 * i for i in range(2, 100)],  # different possible values for `x_name`\n",
    "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
    "        line_vals=['triton', 'torch', 'numba'],  # possible values for `line_arg``\n",
    "        line_names=[\"Triton\", \"Torch\", \"Numba\"],  # label name for the lines\n",
    "        styles=[('blue', '-'), ('green', '-'), ('red', '-')],  # line styles\n",
    "        ylabel=\"GB/s\",  # label name for the y-axis\n",
    "        plot_name=\"softmax-performance\",  # name for the plot. Used also as a file name for saving the plot.\n",
    "        args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\n",
    "    ))\n",
    "def benchmark(M, N, provider):\n",
    "    x = torch.randn(M, N, device=DEVICE, dtype=torch.float32)\n",
    "    stream = getattr(torch, DEVICE.type).Stream()\n",
    "    getattr(torch, DEVICE.type).set_stream(stream)\n",
    "    if provider == 'torch':\n",
    "        ms = triton.testing.do_bench(lambda: torch.softmax(x, axis=-1))\n",
    "    if provider == 'triton':\n",
    "        ms = triton.testing.do_bench(lambda: triton_softmax(x))\n",
    "    if provider == 'numba':\n",
    "        ms = triton.testing.do_bench(lambda: numba_softmax(x))\n",
    "    gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms)\n",
    "\n",
    "\n",
    "benchmark.run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4931f42b-5e0c-4ed1-a29c-619b13c06f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NUMBA CONFIGURATION\n",
      "============================================================\n",
      "Threads per block: 1024\n",
      "Number of blocks: 4096\n",
      "Total thread contexts: 4,194,304\n",
      "Blocks per SM (theoretical): 31.0\n",
      "\n",
      "============================================================\n",
      "TRITON CONFIGURATION\n",
      "============================================================\n",
      "BLOCK_SIZE (compile-time): 16384\n",
      "Number of programs: 4096\n",
      "Programs per SM (theoretical): 31.0\n",
      "\n",
      "============================================================\n",
      "H100 SPECS\n",
      "============================================================\n",
      "Number of SMs: 132\n",
      "Max threads per SM: ~2048\n",
      "Total concurrent thread capacity: ~270,336\n",
      "\n",
      "============================================================\n",
      "SATURATION ANALYSIS\n",
      "============================================================\n",
      "Numba thread contexts: 4,194,304\n",
      "Triton programs: 4,096\n",
      "Numba saturation: 1551.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton\n",
    "from numba import cuda\n",
    "\n",
    "def check_occupancy():\n",
    "    M, N = 4096, 12000\n",
    "    x = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NUMBA CONFIGURATION\")\n",
    "    print(\"=\"*60)\n",
    "    threads_per_block = min(1024, 2**math.ceil(math.log2(N)))\n",
    "    print(f\"Threads per block: {threads_per_block}\")\n",
    "    print(f\"Number of blocks: {M}\")\n",
    "    print(f\"Total thread contexts: {M * threads_per_block:,}\")\n",
    "    print(f\"Blocks per SM (theoretical): {M / 132:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRITON CONFIGURATION\")\n",
    "    print(\"=\"*60)\n",
    "    BLOCK_SIZE = triton.next_power_of_2(N)\n",
    "    print(f\"BLOCK_SIZE (compile-time): {BLOCK_SIZE}\")\n",
    "    print(f\"Number of programs: {M}\")\n",
    "    print(f\"Programs per SM (theoretical): {M / 132:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"H100 SPECS\")\n",
    "    print(\"=\"*60)\n",
    "    device = cuda.get_current_device()\n",
    "    print(f\"Number of SMs: {device.MULTIPROCESSOR_COUNT}\")\n",
    "    print(f\"Max threads per SM: ~2048\")\n",
    "    print(f\"Total concurrent thread capacity: ~{device.MULTIPROCESSOR_COUNT * 2048:,}\")\n",
    "    \n",
    "    # Saturation\n",
    "    numba_threads = M * threads_per_block\n",
    "    triton_programs = M\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SATURATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Numba thread contexts: {numba_threads:,}\")\n",
    "    print(f\"Triton programs: {triton_programs:,}\")\n",
    "    print(f\"Numba saturation: {numba_threads / (132 * 2048) * 100:.1f}%\")\n",
    "\n",
    "check_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a5db72-2845-44d9-ad26-45c3859bdf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NUMBA EXECUTION ANALYSIS\n",
      "============================================================\n",
      "Threads per block: 512\n",
      "Total blocks: 4096\n",
      "Blocks per SM (concurrent): 4\n",
      "Concurrent blocks: 528\n",
      "Execution waves: 8\n",
      "Efficiency: 97.0%\n",
      "\n",
      "============================================================\n",
      "TRITON EXECUTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "If Triton uses 32 threads per program:\n",
      "  Programs per SM: 64\n",
      "  Concurrent programs: 8448\n",
      "  Execution waves: 1\n",
      "  Efficiency: 48.5%\n",
      "\n",
      "If Triton uses 64 threads per program:\n",
      "  Programs per SM: 32\n",
      "  Concurrent programs: 4224\n",
      "  Execution waves: 1\n",
      "  Efficiency: 97.0%\n",
      "\n",
      "If Triton uses 128 threads per program:\n",
      "  Programs per SM: 16\n",
      "  Concurrent programs: 2112\n",
      "  Execution waves: 2\n",
      "  Efficiency: 97.0%\n",
      "\n",
      "If Triton uses 256 threads per program:\n",
      "  Programs per SM: 8\n",
      "  Concurrent programs: 1056\n",
      "  Execution waves: 4\n",
      "  Efficiency: 97.0%\n"
     ]
    }
   ],
   "source": [
    "def analyze_execution_waves():\n",
    "    M, N = 4096, 12000\n",
    "    \n",
    "    # H100 specs\n",
    "    SMs = 132\n",
    "    max_threads_per_sm = 2048\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NUMBA EXECUTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Numba config\n",
    "    threads_per_block = 512\n",
    "    total_blocks = M\n",
    "    \n",
    "    # How many blocks fit per SM?\n",
    "    blocks_per_sm_limit_threads = max_threads_per_sm // threads_per_block  # 4\n",
    "    \n",
    "    # Assuming no other limits (shared memory, registers are fine)\n",
    "    blocks_per_sm = blocks_per_sm_limit_threads\n",
    "    \n",
    "    concurrent_blocks = SMs * blocks_per_sm\n",
    "    num_waves = (total_blocks + concurrent_blocks - 1) // concurrent_blocks\n",
    "    \n",
    "    print(f\"Threads per block: {threads_per_block}\")\n",
    "    print(f\"Total blocks: {total_blocks}\")\n",
    "    print(f\"Blocks per SM (concurrent): {blocks_per_sm}\")\n",
    "    print(f\"Concurrent blocks: {concurrent_blocks}\")\n",
    "    print(f\"Execution waves: {num_waves}\")\n",
    "    print(f\"Efficiency: {total_blocks / (num_waves * concurrent_blocks) * 100:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRITON EXECUTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Triton: harder to analyze without knowing internal thread count\n",
    "    # But we can make educated guesses\n",
    "    \n",
    "    total_programs = M\n",
    "    \n",
    "    # Hypothesis 1: Triton uses fewer threads per program\n",
    "    for triton_threads in [32, 64, 128, 256]:\n",
    "        programs_per_sm = max_threads_per_sm // triton_threads\n",
    "        concurrent_programs = SMs * programs_per_sm\n",
    "        waves = (total_programs + concurrent_programs - 1) // concurrent_programs\n",
    "        \n",
    "        print(f\"\\nIf Triton uses {triton_threads} threads per program:\")\n",
    "        print(f\"  Programs per SM: {programs_per_sm}\")\n",
    "        print(f\"  Concurrent programs: {concurrent_programs}\")\n",
    "        print(f\"  Execution waves: {waves}\")\n",
    "        print(f\"  Efficiency: {total_programs / (waves * concurrent_programs) * 100:.1f}%\")\n",
    "\n",
    "analyze_execution_waves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0659d290-8e23-4138-99e4-2132973f2c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NUMBA KERNEL INSPECTION\n",
      "============================================================\n",
      "\n",
      "Available methods:\n",
      "  - add_overload\n",
      "  - call\n",
      "  - compile\n",
      "  - compile_device\n",
      "  - configure\n",
      "  - disable_compile\n",
      "  - doc\n",
      "  - dump\n",
      "  - enable_caching\n",
      "  - extensions\n",
      "  - fold_argument_types\n",
      "  - forall\n",
      "  - func_code\n",
      "  - get_annotation_info\n",
      "  - get_call_template\n",
      "  - get_compile_result\n",
      "  - get_const_mem_size\n",
      "  - get_function_type\n",
      "  - get_local_mem_per_thread\n",
      "  - get_max_threads_per_block\n",
      "\n",
      "============================================================\n",
      "PTX CODE (GPU Assembly)\n",
      "============================================================\n",
      "PTX inspection failed: module 'numba.cuda' has no attribute 'float32'\n",
      "\n",
      "============================================================\n",
      "KNOWN RESOURCE USAGE\n",
      "============================================================\n",
      "Shared memory: 2  1024  4 = 8,192 bytes (8 KB)\n",
      "Threads per block: 512\n",
      "Syncthreads calls: ~18 per block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lelarge/miniconda3/envs/cs336-syst/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 10 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, float32\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def check_kernel_info():\n",
    "    \"\"\"\n",
    "    Working version - only uses available attributes\n",
    "    \"\"\"\n",
    "    # Simple test kernel\n",
    "    @cuda.jit\n",
    "    def test_kernel(x, y, num_rows, num_cols):\n",
    "        row = cuda.blockIdx.x\n",
    "        tid = cuda.threadIdx.x\n",
    "        block_size = cuda.blockDim.x\n",
    "        \n",
    "        shared_max = cuda.shared.array(1024, float32)\n",
    "        shared_sum = cuda.shared.array(1024, float32)\n",
    "        \n",
    "        if row >= num_rows:\n",
    "            return\n",
    "        \n",
    "        thread_max = float('-inf')\n",
    "        for col in range(tid, num_cols, block_size):\n",
    "            val = x[row, col]\n",
    "            if val > thread_max:\n",
    "                thread_max = val\n",
    "        \n",
    "        shared_max[tid] = thread_max\n",
    "        cuda.syncthreads()\n",
    "    \n",
    "    # Compile by launching once\n",
    "    x = cuda.to_device(np.random.randn(10, 512).astype(np.float32))\n",
    "    y = cuda.device_array((10, 512), dtype=np.float32)\n",
    "    test_kernel[10, 512](x, y, 10, 512)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"NUMBA KERNEL INSPECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check what's actually available\n",
    "    print(\"\\nAvailable methods:\")\n",
    "    methods = [m for m in dir(test_kernel) if not m.startswith('_')]\n",
    "    for method in methods[:20]:\n",
    "        print(f\"  - {method}\")\n",
    "    \n",
    "    # Try PTX inspection\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PTX CODE (GPU Assembly)\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        # Get the signature we compiled\n",
    "        sig = (cuda.float32[:, :], cuda.float32[:, :], cuda.int32, cuda.int32)\n",
    "        ptx = test_kernel.inspect_asm(sig)\n",
    "        \n",
    "        # Extract register info from PTX\n",
    "        ptx_str = str(ptx)\n",
    "        lines = ptx_str.split('\\n')\n",
    "        \n",
    "        print(\"\\nRegister declarations:\")\n",
    "        for line in lines[:100]:\n",
    "            if '.reg' in line:\n",
    "                print(f\"  {line.strip()}\")\n",
    "        \n",
    "        # Look for register count\n",
    "        for line in lines:\n",
    "            if 'reg,' in line or 'registers' in line.lower():\n",
    "                print(f\"  {line.strip()}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"PTX inspection failed: {e}\")\n",
    "    \n",
    "    # Manually calculate what we know\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KNOWN RESOURCE USAGE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Shared memory: 2  1024  4 = 8,192 bytes (8 KB)\")\n",
    "    print(f\"Threads per block: 512\")\n",
    "    print(f\"Syncthreads calls: ~18 per block\")\n",
    "\n",
    "check_kernel_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090acb53-a319-4d12-9769-b70984082030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\tNumba(ms)\tTriton(ms)\tRatio\n",
      "==================================================\n",
      "256\t0.126\t\t0.021\t\t0.17x\n",
      "512\t0.172\t\t0.028\t\t0.17x\n",
      "1024\t0.307\t\t0.022\t\t0.07x\n",
      "2048\t0.346\t\t0.023\t\t0.07x\n",
      "4096\t0.368\t\t0.044\t\t0.12x\n",
      "12000\t0.577\t\t0.146\t\t0.25x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def profile_detailed():\n",
    "    sizes = [256, 512, 1024, 2048, 4096, 12000]\n",
    "    M = 4096\n",
    "    \n",
    "    print(\"N\\tNumba(ms)\\tTriton(ms)\\tRatio\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for N in sizes:\n",
    "        x = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "        \n",
    "        # Warm up\n",
    "        for _ in range(10):\n",
    "            _ = numba_softmax(x)\n",
    "            _ = triton_softmax(x)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Benchmark\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        # Numba\n",
    "        start.record()\n",
    "        for _ in range(100):\n",
    "            _ = numba_softmax(x)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        numba_time = start.elapsed_time(end) / 100\n",
    "        \n",
    "        # Triton\n",
    "        start.record()\n",
    "        for _ in range(100):\n",
    "            _ = triton_softmax(x)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        triton_time = start.elapsed_time(end) / 100\n",
    "        \n",
    "        ratio = triton_time / numba_time\n",
    "        print(f\"{N}\\t{numba_time:.3f}\\t\\t{triton_time:.3f}\\t\\t{ratio:.2f}x\")\n",
    "\n",
    "profile_detailed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c66aad-8b06-453a-8701-92713dcb7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1\n",
      "\n",
      "============================================================\n",
      "GPU 0: NVIDIA H100 NVL\n",
      "============================================================\n",
      "\n",
      " BASIC INFO:\n",
      "  Compute Capability: (9, 0)\n",
      "  PCI Device ID: 0\n",
      "\n",
      " THREAD LIMITS:\n",
      "  Max threads per block: 1024\n",
      "  Max block dimensions: 1024  1024  64\n",
      "  Max grid dimensions: 2147483647  65535  65535\n",
      "  Warp size: 32\n",
      "\n",
      " MEMORY:\n",
      "  Total global memory: 93.12 GB\n",
      "  Free memory: 92.61 GB\n",
      "  Used memory: 0.51 GB\n",
      "  Shared memory per block: 48.00 KB\n",
      "  Shared memory per SM: 228.00 KB\n",
      "  Constant memory: 64.00 KB\n",
      "\n",
      " MULTIPROCESSORS:\n",
      "  Number of SMs: 132\n",
      "\n",
      " REGISTERS:\n",
      "  Registers per block: 65536\n",
      "  Registers per SM: 65536\n",
      "\n",
      " PERFORMANCE:\n",
      "  Clock rate: 1785.00 MHz\n",
      "  Memory clock rate: 2619.00 MHz\n",
      "  Memory bus width: 6144 bits\n",
      "  L2 cache size: 61440.00 KB\n",
      "\n",
      " FEATURES:\n",
      "  Concurrent kernels: True\n",
      "  Unified addressing: True\n",
      "  ECC enabled: True\n",
      "  Managed memory: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "def show_gpu_info():\n",
    "    if not cuda.is_available():\n",
    "        print(\"No CUDA GPU available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Number of GPUs: {len(cuda.gpus)}\\n\")\n",
    "    \n",
    "    for i, gpu in enumerate(cuda.gpus):\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"GPU {i}: {gpu.name.decode('utf-8')}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        with cuda.gpus[i]:\n",
    "            device = cuda.get_current_device()\n",
    "            \n",
    "            # Helper function to safely get attribute\n",
    "            def safe_get(attr_name, default=\"N/A\"):\n",
    "                try:\n",
    "                    return getattr(device, attr_name)\n",
    "                except AttributeError:\n",
    "                    return default\n",
    "            \n",
    "            # Basic info\n",
    "            print(f\"\\n BASIC INFO:\")\n",
    "            print(f\"  Compute Capability: {device.compute_capability}\")\n",
    "            print(f\"  PCI Device ID: {device.id}\")\n",
    "            \n",
    "            # Thread/Block limits\n",
    "            print(f\"\\n THREAD LIMITS:\")\n",
    "            print(f\"  Max threads per block: {safe_get('MAX_THREADS_PER_BLOCK')}\")\n",
    "            print(f\"  Max block dimensions: {safe_get('MAX_BLOCK_DIM_X')}  {safe_get('MAX_BLOCK_DIM_Y')}  {safe_get('MAX_BLOCK_DIM_Z')}\")\n",
    "            print(f\"  Max grid dimensions: {safe_get('MAX_GRID_DIM_X')}  {safe_get('MAX_GRID_DIM_Y')}  {safe_get('MAX_GRID_DIM_Z')}\")\n",
    "            print(f\"  Warp size: {safe_get('WARP_SIZE')}\")\n",
    "            \n",
    "            # Memory limits\n",
    "            print(f\"\\n MEMORY:\")\n",
    "            meminfo = cuda.current_context().get_memory_info()\n",
    "            free_memory = meminfo[0]\n",
    "            total_memory = meminfo[1]\n",
    "            print(f\"  Total global memory: {total_memory / 1024**3:.2f} GB\")\n",
    "            print(f\"  Free memory: {free_memory / 1024**3:.2f} GB\")\n",
    "            print(f\"  Used memory: {(total_memory - free_memory) / 1024**3:.2f} GB\")\n",
    "            \n",
    "            shared_mem = safe_get('MAX_SHARED_MEMORY_PER_BLOCK')\n",
    "            if shared_mem != \"N/A\":\n",
    "                print(f\"  Shared memory per block: {shared_mem / 1024:.2f} KB\")\n",
    "            \n",
    "            shared_mem_sm = safe_get('MAX_SHARED_MEMORY_PER_MULTIPROCESSOR')\n",
    "            if shared_mem_sm != \"N/A\":\n",
    "                print(f\"  Shared memory per SM: {shared_mem_sm / 1024:.2f} KB\")\n",
    "            \n",
    "            const_mem = safe_get('TOTAL_CONSTANT_MEMORY')\n",
    "            if const_mem != \"N/A\":\n",
    "                print(f\"  Constant memory: {const_mem / 1024:.2f} KB\")\n",
    "            \n",
    "            # Multiprocessor info\n",
    "            print(f\"\\n MULTIPROCESSORS:\")\n",
    "            mp_count = safe_get('MULTIPROCESSOR_COUNT')\n",
    "            print(f\"  Number of SMs: {mp_count}\")\n",
    "            \n",
    "            max_threads_sm = safe_get('MAX_THREADS_PER_MULTIPROCESSOR')\n",
    "            if max_threads_sm != \"N/A\":\n",
    "                print(f\"  Max threads per SM: {max_threads_sm}\")\n",
    "                warp_size = safe_get('WARP_SIZE', 32)\n",
    "                if warp_size != \"N/A\":\n",
    "                    print(f\"  Max warps per SM: {max_threads_sm // warp_size}\")\n",
    "            \n",
    "            max_blocks_sm = safe_get('MAX_BLOCKS_PER_MULTIPROCESSOR')\n",
    "            if max_blocks_sm != \"N/A\":\n",
    "                print(f\"  Max blocks per SM: {max_blocks_sm}\")\n",
    "            \n",
    "            # Register info\n",
    "            print(f\"\\n REGISTERS:\")\n",
    "            regs_block = safe_get('MAX_REGISTERS_PER_BLOCK')\n",
    "            if regs_block != \"N/A\":\n",
    "                print(f\"  Registers per block: {regs_block}\")\n",
    "            \n",
    "            regs_sm = safe_get('MAX_REGISTERS_PER_MULTIPROCESSOR')\n",
    "            if regs_sm != \"N/A\":\n",
    "                print(f\"  Registers per SM: {regs_sm}\")\n",
    "            \n",
    "            # Performance\n",
    "            print(f\"\\n PERFORMANCE:\")\n",
    "            clock = safe_get('CLOCK_RATE')\n",
    "            if clock != \"N/A\":\n",
    "                print(f\"  Clock rate: {clock / 1000:.2f} MHz\")\n",
    "            \n",
    "            mem_clock = safe_get('MEMORY_CLOCK_RATE')\n",
    "            if mem_clock != \"N/A\":\n",
    "                print(f\"  Memory clock rate: {mem_clock / 1000:.2f} MHz\")\n",
    "            \n",
    "            mem_bus = safe_get('GLOBAL_MEMORY_BUS_WIDTH')\n",
    "            if mem_bus != \"N/A\":\n",
    "                print(f\"  Memory bus width: {mem_bus} bits\")\n",
    "            \n",
    "            l2_cache = safe_get('L2_CACHE_SIZE')\n",
    "            if l2_cache != \"N/A\":\n",
    "                print(f\"  L2 cache size: {l2_cache / 1024:.2f} KB\")\n",
    "            \n",
    "            # Features\n",
    "            print(f\"\\n FEATURES:\")\n",
    "            concurrent = safe_get('CONCURRENT_KERNELS')\n",
    "            if concurrent != \"N/A\":\n",
    "                print(f\"  Concurrent kernels: {bool(concurrent)}\")\n",
    "            \n",
    "            unified = safe_get('UNIFIED_ADDRESSING')\n",
    "            if unified != \"N/A\":\n",
    "                print(f\"  Unified addressing: {bool(unified)}\")\n",
    "            \n",
    "            ecc = safe_get('ECC_ENABLED')\n",
    "            if ecc != \"N/A\":\n",
    "                print(f\"  ECC enabled: {bool(ecc)}\")\n",
    "            \n",
    "            managed = safe_get('MANAGED_MEMORY')\n",
    "            if managed != \"N/A\":\n",
    "                print(f\"  Managed memory: {bool(managed)}\")\n",
    "            \n",
    "            # Calculate theoretical occupancy if we have the data\n",
    "            if mp_count != \"N/A\" and max_threads_sm != \"N/A\":\n",
    "                print(f\"\\n THEORETICAL LIMITS:\")\n",
    "                max_blocks = max_threads_sm // 256\n",
    "                print(f\"  Max blocks per SM (with 256 threads/block): {max_blocks}\")\n",
    "                total_threads = mp_count * max_threads_sm\n",
    "                print(f\"  Theoretical max concurrent threads: {total_threads:,}\")\n",
    "            \n",
    "        print()\n",
    "\n",
    "show_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788ee767-a944-4997-8d13-961078fbc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda_driver\n",
    "cuda_driver.init()\n",
    "device = cuda_driver.Device(0)\n",
    "max_threads_sm = device.get_attribute(cuda_driver.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a8bb24-286f-4f94-9040-82e1ee2d504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1\n",
      "\n",
      "============================================================\n",
      "GPU 0: NVIDIA H100 NVL\n",
      "============================================================\n",
      "\n",
      " BASIC INFO:\n",
      "  Compute Capability: 9.0\n",
      "  PCI Device ID: 0000:64:00.0\n",
      "\n",
      " THREAD LIMITS:\n",
      "  Max threads per block: 1024\n",
      "  Max block dimensions: 1024  1024  64\n",
      "  Max grid dimensions: 2147483647  65535  65535\n",
      "  Warp size: 32\n",
      "\n",
      " MEMORY:\n",
      "  Total global memory: 93.12 GB\n",
      "  Free memory: 92.61 GB\n",
      "  Used memory: 0.51 GB\n",
      "  Shared memory per block: 48.00 KB\n",
      "  Shared memory per SM: 228.00 KB\n",
      "  Constant memory: 64.00 KB\n",
      "\n",
      " MULTIPROCESSORS:\n",
      "  Number of SMs: 132\n",
      "  Max threads per SM: 2048\n",
      "  Max warps per SM: 64\n",
      "  Max blocks per SM: 32\n",
      "\n",
      " REGISTERS:\n",
      "  Registers per block: 65536\n",
      "  Registers per SM: 65536\n",
      "\n",
      " PERFORMANCE:\n",
      "  Clock rate: 1785.00 MHz\n",
      "  Memory clock rate: 2619.00 MHz\n",
      "  Memory bus width: 6144 bits\n",
      "  L2 cache size: 61440.00 KB\n",
      "\n",
      " FEATURES:\n",
      "  Concurrent kernels: True\n",
      "  Unified addressing: True\n",
      "  ECC enabled: True\n",
      "  Managed memory: True\n",
      "\n",
      " THEORETICAL LIMITS:\n",
      "  Max blocks per SM (with 256 threads/block): 8\n",
      "  Theoretical max concurrent threads: 270,336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "\n",
    "def show_gpu_info():\n",
    "    # Initialize CUDA\n",
    "    cuda.init()\n",
    "    \n",
    "    num_gpus = cuda.Device.count()\n",
    "    \n",
    "    if num_gpus == 0:\n",
    "        print(\"No CUDA GPU available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Number of GPUs: {num_gpus}\\n\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        device = cuda.Device(i)\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"GPU {i}: {device.name()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Helper function to safely get attribute\n",
    "        def safe_get(attr, default=\"N/A\"):\n",
    "            try:\n",
    "                return device.get_attribute(attr)\n",
    "            except:\n",
    "                return default\n",
    "        \n",
    "        # Compute capability\n",
    "        major = device.compute_capability()[0]\n",
    "        minor = device.compute_capability()[1]\n",
    "        \n",
    "        # Basic info\n",
    "        print(f\"\\n BASIC INFO:\")\n",
    "        print(f\"  Compute Capability: {major}.{minor}\")\n",
    "        print(f\"  PCI Device ID: {device.pci_bus_id()}\")\n",
    "        \n",
    "        # Thread/Block limits\n",
    "        print(f\"\\n THREAD LIMITS:\")\n",
    "        print(f\"  Max threads per block: {safe_get(cuda.device_attribute.MAX_THREADS_PER_BLOCK)}\")\n",
    "        print(f\"  Max block dimensions: {safe_get(cuda.device_attribute.MAX_BLOCK_DIM_X)}  {safe_get(cuda.device_attribute.MAX_BLOCK_DIM_Y)}  {safe_get(cuda.device_attribute.MAX_BLOCK_DIM_Z)}\")\n",
    "        print(f\"  Max grid dimensions: {safe_get(cuda.device_attribute.MAX_GRID_DIM_X)}  {safe_get(cuda.device_attribute.MAX_GRID_DIM_Y)}  {safe_get(cuda.device_attribute.MAX_GRID_DIM_Z)}\")\n",
    "        print(f\"  Warp size: {safe_get(cuda.device_attribute.WARP_SIZE)}\")\n",
    "        \n",
    "        # Memory limits\n",
    "        print(f\"\\n MEMORY:\")\n",
    "        total_memory = device.total_memory()\n",
    "        print(f\"  Total global memory: {total_memory / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # Get free memory (requires context)\n",
    "        try:\n",
    "            context = device.make_context()\n",
    "            free_memory, total_memory_ctx = cuda.mem_get_info()\n",
    "            print(f\"  Free memory: {free_memory / 1024**3:.2f} GB\")\n",
    "            print(f\"  Used memory: {(total_memory_ctx - free_memory) / 1024**3:.2f} GB\")\n",
    "            context.pop()\n",
    "        except:\n",
    "            print(f\"  Free memory: N/A\")\n",
    "            print(f\"  Used memory: N/A\")\n",
    "        \n",
    "        shared_mem = safe_get(cuda.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK)\n",
    "        if shared_mem != \"N/A\":\n",
    "            print(f\"  Shared memory per block: {shared_mem / 1024:.2f} KB\")\n",
    "        \n",
    "        shared_mem_sm = safe_get(cuda.device_attribute.MAX_SHARED_MEMORY_PER_MULTIPROCESSOR)\n",
    "        if shared_mem_sm != \"N/A\":\n",
    "            print(f\"  Shared memory per SM: {shared_mem_sm / 1024:.2f} KB\")\n",
    "        \n",
    "        const_mem = safe_get(cuda.device_attribute.TOTAL_CONSTANT_MEMORY)\n",
    "        if const_mem != \"N/A\":\n",
    "            print(f\"  Constant memory: {const_mem / 1024:.2f} KB\")\n",
    "        \n",
    "        # Multiprocessor info\n",
    "        print(f\"\\n MULTIPROCESSORS:\")\n",
    "        mp_count = safe_get(cuda.device_attribute.MULTIPROCESSOR_COUNT)\n",
    "        print(f\"  Number of SMs: {mp_count}\")\n",
    "        \n",
    "        max_threads_sm = safe_get(cuda.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR)\n",
    "        if max_threads_sm != \"N/A\":\n",
    "            print(f\"  Max threads per SM: {max_threads_sm}\")\n",
    "            warp_size = safe_get(cuda.device_attribute.WARP_SIZE, 32)\n",
    "            if warp_size != \"N/A\":\n",
    "                print(f\"  Max warps per SM: {max_threads_sm // warp_size}\")\n",
    "        \n",
    "        max_blocks_sm = safe_get(cuda.device_attribute.MAX_BLOCKS_PER_MULTIPROCESSOR)\n",
    "        if max_blocks_sm != \"N/A\":\n",
    "            print(f\"  Max blocks per SM: {max_blocks_sm}\")\n",
    "        \n",
    "        # Register info\n",
    "        print(f\"\\n REGISTERS:\")\n",
    "        regs_block = safe_get(cuda.device_attribute.MAX_REGISTERS_PER_BLOCK)\n",
    "        if regs_block != \"N/A\":\n",
    "            print(f\"  Registers per block: {regs_block}\")\n",
    "        \n",
    "        regs_sm = safe_get(cuda.device_attribute.MAX_REGISTERS_PER_MULTIPROCESSOR)\n",
    "        if regs_sm != \"N/A\":\n",
    "            print(f\"  Registers per SM: {regs_sm}\")\n",
    "        \n",
    "        # Performance\n",
    "        print(f\"\\n PERFORMANCE:\")\n",
    "        clock = safe_get(cuda.device_attribute.CLOCK_RATE)\n",
    "        if clock != \"N/A\":\n",
    "            print(f\"  Clock rate: {clock / 1000:.2f} MHz\")\n",
    "        \n",
    "        mem_clock = safe_get(cuda.device_attribute.MEMORY_CLOCK_RATE)\n",
    "        if mem_clock != \"N/A\":\n",
    "            print(f\"  Memory clock rate: {mem_clock / 1000:.2f} MHz\")\n",
    "        \n",
    "        mem_bus = safe_get(cuda.device_attribute.GLOBAL_MEMORY_BUS_WIDTH)\n",
    "        if mem_bus != \"N/A\":\n",
    "            print(f\"  Memory bus width: {mem_bus} bits\")\n",
    "        \n",
    "        l2_cache = safe_get(cuda.device_attribute.L2_CACHE_SIZE)\n",
    "        if l2_cache != \"N/A\":\n",
    "            print(f\"  L2 cache size: {l2_cache / 1024:.2f} KB\")\n",
    "        \n",
    "        # Features\n",
    "        print(f\"\\n FEATURES:\")\n",
    "        concurrent = safe_get(cuda.device_attribute.CONCURRENT_KERNELS)\n",
    "        if concurrent != \"N/A\":\n",
    "            print(f\"  Concurrent kernels: {bool(concurrent)}\")\n",
    "        \n",
    "        unified = safe_get(cuda.device_attribute.UNIFIED_ADDRESSING)\n",
    "        if unified != \"N/A\":\n",
    "            print(f\"  Unified addressing: {bool(unified)}\")\n",
    "        \n",
    "        ecc = safe_get(cuda.device_attribute.ECC_ENABLED)\n",
    "        if ecc != \"N/A\":\n",
    "            print(f\"  ECC enabled: {bool(ecc)}\")\n",
    "        \n",
    "        managed = safe_get(cuda.device_attribute.MANAGED_MEMORY)\n",
    "        if managed != \"N/A\":\n",
    "            print(f\"  Managed memory: {bool(managed)}\")\n",
    "        \n",
    "        # Calculate theoretical occupancy if we have the data\n",
    "        if mp_count != \"N/A\" and max_threads_sm != \"N/A\":\n",
    "            print(f\"\\n THEORETICAL LIMITS:\")\n",
    "            max_blocks = max_threads_sm // 256\n",
    "            print(f\"  Max blocks per SM (with 256 threads/block): {max_blocks}\")\n",
    "            total_threads = mp_count * max_threads_sm\n",
    "            print(f\"  Theoretical max concurrent threads: {total_threads:,}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "show_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceefa0b-5ff7-4c7a-8105-3eae03878782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-syst",
   "language": "python",
   "name": "cs336-syst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
